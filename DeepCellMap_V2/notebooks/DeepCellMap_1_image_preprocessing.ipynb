{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/cover_readme.png\" alt=\"Example Image\" style=\"width:1400px; height:400px;\" >"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# **DeepCellMap 1 - Image preprocessing - Cells segmentation & classification**\n",
    "---\n",
    "\n",
    "<b>In this notebook</b>\n",
    "\n",
    "**1. Image pre-processing**\n",
    "- a. Image downscaling\n",
    "- b. Mask extraction\n",
    "- c. Tiling \n",
    "\n",
    "**2. Cells segmentation & classification on the entire image**\n",
    "\n",
    "*Note : The algorithms of this notebook are detailed in figures S2.A and S3 of the online method of the article.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pb importing pylibCZIrw\n",
      "Pb importing pylibCZIrw\n"
     ]
    }
   ],
   "source": [
    "# This imports your common setup code from grabber.py\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "from grabber import * \n",
    "%precision 2\n",
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import matplotlib\n",
    "coolwarm = matplotlib.colormaps.get_cmap(\"viridis\")\n",
    "from config.dataset_management import take_config_from_dataset\n",
    "\n",
    "from utils.util import *\n",
    "from utils.util_fig_display import *\n",
    "from utils.util_colors_drawing import *\n",
    "\n",
    "from preprocessing import filter, slide, tiles\n",
    "\n",
    "from stat_analysis import deep_cell_map\n",
    "from segmentation_classification import segmentation,classification\n",
    "from segmentation_classification.classification import ModelClassification, segment_classify_cells_wsi\n",
    "\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b50910b7dd4433bb17baad67da0cb1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select dataset:', options={'generated_rois': 'generated_rois', 'ihc_microglia_fetal_humaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataframe_dropdown)\n",
    "dataset_name = dataframe_dropdown.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mWe are playing with the dataset: ihc_microglia_fetal_human_brain_database\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset_name = dataframe_dropdown.value\n",
    "dataset_config = take_config_from_dataset(dataset_name)\n",
    "print(blue(\"We are playing with the dataset: {}\".format(dataset_config.dataset_name)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images selection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = slide.get_info_data(dataset_config, image_list=image_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# **1. Image preprocessing**\n",
    "---\n",
    "\n",
    "This part is illustrated in parts A, B and C of the figure below. \n",
    "\n",
    "<img src=\"Images/different_scales.png\" alt=\"Example Image\" style=\"width:1400px; height:800px;\" >\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Image downscalling by factor x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mPre-processing : downscalling image 1...\u001b[0m\n",
      "\u001b[34mPre-processing : downscalling image 2...\u001b[0m\n",
      "\u001b[34mPre-processing : downscalling image 3...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "slide.training_slide_range_to_images(dataset_config,image_list=image_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Tissue extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pb importing pylibCZIrw\n",
      "Pb importing pylibCZIrw\n",
      "Pb importing pylibCZIrw\n",
      "slide_num 1\n",
      "slide_num 2\n",
      "slide_num 3\n",
      "\u001b[34mfiltered_np_rgb\u001b[0m -> shape  (1506, 2925, 3)  dtype : uint8  min : 0  max : 249\n",
      "\u001b[34mfiltered_np_rgb\u001b[0m -> shape  (2360, 3299, 3)  dtype : uint8  min : 0  max : 254\n",
      "\u001b[34mfiltered_np_rgb\u001b[0m -> shape  (2557, 3236, 3)  dtype : uint8  min : 0  max : 250\n"
     ]
    }
   ],
   "source": [
    "segmentation.multiprocess_apply_filters_to_images(save=True, display=False, html=False, image_num_list=image_list,dataset_config=dataset_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Tiling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pb importing pylibCZIrw\n",
      "Pb importing pylibCZIrw\n",
      "Pb importing pylibCZIrw\n",
      "Pb importing pylibCZIrw\n",
      "Pb importing pylibCZIrw\n",
      "Pb importing pylibCZIrw\n",
      "/Users/U1029063/Documents/ens_project/Code_reviewers_new_submision/output/ihc_microglia_fetal_human_brain_database/1_image_pre_processing/downscaled_images/thumbnail_original/001-32x-93623x48197-2925x1506.png\n",
      "/Users/U1029063/Documents/ens_project/Code_reviewers_new_submision/output/ihc_microglia_fetal_human_brain_database/1_image_pre_processing/downscaled_images/thumbnail_original/002-32x-103583x81839-3236x2557.png\n",
      "/Users/U1029063/Documents/ens_project/Code_reviewers_new_submision/output/ihc_microglia_fetal_human_brain_database/1_image_pre_processing/downscaled_images/thumbnail_original/003-32x-105575x75544-3299x2360.png\n"
     ]
    }
   ],
   "source": [
    "tiles.multiprocess_filtered_images_to_tiles(image_num_list = image_list,dataset_config=dataset_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: the file \"./info_images.html\" has been generated and allows to:**\n",
    "\n",
    "- See downscaled images \n",
    "- See the result of the tissue segmentation \n",
    "- See how the image has been split into tiles \n",
    "- Statistics about tiles and tissue \n",
    "- See some examples of tiles in each image (50 randomly chosen tiles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
